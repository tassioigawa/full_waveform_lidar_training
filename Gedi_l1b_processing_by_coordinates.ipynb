{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWtQkS-LeNTq"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mwo_VEygStPw2yjnq87YEIjyxOjthsGl#scrollTo=LWtQkS-LeNTq)\n",
        "\n",
        "##GEDI L1B data processing using coordinates information\n",
        "\n",
        "Author: Savannah Cooley\n",
        "\n",
        "Version modified by Tassio Koiti Igawa\n",
        "\n",
        "Repository - Original code: https://github.com/savcooley/full_waveform_lidar_training.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSYbmv5y9vN2"
      },
      "outputs": [],
      "source": [
        "# Install\n",
        "\n",
        "# Install the necessary Python libraries using pip.\n",
        "!pip install earthaccess h5py geopandas matplotlib seaborn requests shapely folium\n",
        "!pip install --upgrade earthaccess\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from shapely.geometry import Point, Polygon\n",
        "import folium\n",
        "from datetime import datetime, date\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import earthaccess\n",
        "\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6ZUZt4RTdMd8"
      },
      "outputs": [],
      "source": [
        "# Mount Your Google Drive\n",
        "# Mounting your Google Drive allows the notebook to save output files and access data you may have stored. You will be prompted to authorize Colab to access your drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instructions\n",
        "\n",
        "- Insert the area of interest and the start and end dates of the data collection into the code.\n",
        "\n",
        "- Provide the necessary information to log in to Earthdata."
      ],
      "metadata": {
        "id": "_AqoTEDgosp9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWNIiYrMFri3"
      },
      "outputs": [],
      "source": [
        "# Authenticate with NASA Earthdata\n",
        "# To download GEDI data, you need a NASA Earthdata account. If you don't have one, you can register for free.\n",
        "# Run the authentication cell in the notebook, which will prompt you for your Earthdata credentials.\n",
        "\n",
        "\n",
        "# Authenticate with NASA Earthdata\n",
        "auth = earthaccess.login()\n",
        "\n",
        "if auth.authenticated:\n",
        "    print(\"‚úì Successfully authenticated with NASA Earthdata!\")\n",
        "else:\n",
        "    print(\"‚úó Authentication failed. Please check your credentials.\")\n",
        "\n",
        "# Define your Area of Interest (AOI)\n",
        "# Example: Par√° and Northeast Par√° and surrounding area near Double Springs 58.8982679169921823,-9.8411685263671949 : -46.0613679169921824,2.5911314736328070  ////-49.8971801984433938,-4.3451970939528763 : -45.6634012858677067,-0.5800425648302245\n",
        "# Example 2: Medicil√¢ncia: -53.2922282284325135,-3.7400166646731070, -52.6564362918175277,-3.1698933787883066\n",
        "DEFAULT_AOI = [-53.2922282284325135,-3.7400166646731070, -52.6564362918175277,-3.1698933787883066]  # Default demo AOI\n",
        "aoi_bbox = [-53.2922282284325135,-3.7400166646731070, -52.6564362918175277,-3.1698933787883066]  # [min_lon, min_lat, max_lon, max_lat]\n",
        "\n",
        "# Check if user is using default AOI (for demo optimization)\n",
        "is_default_aoi = (aoi_bbox == DEFAULT_AOI)\n",
        "\n",
        "print(f\"Area of Interest (Bounding Box): {aoi_bbox}\")\n",
        "print(f\"Longitude range: {aoi_bbox[0]} to {aoi_bbox[2]}\")\n",
        "print(f\"Latitude range: {aoi_bbox[1]} to {aoi_bbox[3]}\")\n",
        "\n",
        "if is_default_aoi:\n",
        "    print(\" Using default AOI - will prioritize 5th granule for demo efficiency\")\n",
        "else:\n",
        "    print(\"Using custom AOI - will process granules in standard order\")\n",
        "\n",
        "# Define temporal range (2019-04-01-min value)\n",
        "start_date = \"2024-06-01\" # Start of GEDI data aquisition\n",
        "end_date = \"2025-10-22\" # Can update\n",
        "\n",
        "print(f\"Temporal range: {start_date} to {end_date}\")\n",
        "\n",
        "# Define Full Power beams only\n",
        "FULL_POWER_BEAMS = ['BEAM0101', 'BEAM0110', 'BEAM1000', 'BEAM1011']\n",
        "print(f\"Processing Full Power beams only: {FULL_POWER_BEAMS}\")\n",
        "\n",
        "# Search for GEDI L1B granules - FIXED VERSION\n",
        "def search_gedi_l1b(bbox, start_date, end_date, max_results=2000):##40\n",
        "    \"\"\"\n",
        "    Search for GEDI L1B granules - Fixed for newer earthaccess versions\n",
        "    Increased max_results to have more options if files don't contain quality data\n",
        "\n",
        "    Parameters:\n",
        "    bbox: list of [min_lon, min_lat, max_lon, max_lat]\n",
        "    \"\"\"\n",
        "    print(f\"Searching for GEDI L1B data...\")\n",
        "    print(f\"  Bounding box: {bbox}\")\n",
        "    print(f\"  Date range: {start_date} to {end_date}\")\n",
        "    print(f\"  Max results: {max_results}\")\n",
        "\n",
        "    # FIXED: Pass bounding box coordinates as separate arguments\n",
        "    min_lon, min_lat, max_lon, max_lat = bbox\n",
        "\n",
        "    try:\n",
        "        results = earthaccess.search_data(\n",
        "            short_name=\"GEDI01_B\",\n",
        "            version=\"002\",\n",
        "            bounding_box=(min_lon, min_lat, max_lon, max_lat),  # As tuple with 4 values\n",
        "            temporal=(start_date, end_date),\n",
        "            count=max_results\n",
        "        )\n",
        "\n",
        "        print(f\"Found {len(results)} GEDI L1B granules\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in search: {str(e)}\")\n",
        "        print(\"Trying alternative bounding box format...\")\n",
        "\n",
        "        # Alternative format if the above doesn't work\n",
        "        try:\n",
        "            results = earthaccess.search_data(\n",
        "                short_name=\"GEDI01_B\",\n",
        "                version=\"002\",\n",
        "                bounding_box=f\"{min_lon},{min_lat},{max_lon},{max_lat}\",  # As string\n",
        "                temporal=(start_date, end_date),\n",
        "                count=max_results\n",
        "            )\n",
        "\n",
        "            print(f\"Found {len(results)} GEDI L1B granules\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e2:\n",
        "            print(f\"Second attempt failed: {str(e2)}\")\n",
        "            print(\"Trying without bounding box (will filter spatially later)...\")\n",
        "\n",
        "            # Last resort: search without spatial filter\n",
        "            try:\n",
        "                results = earthaccess.search_data(\n",
        "                    short_name=\"GEDI01_B\",\n",
        "                    version=\"002\",\n",
        "                    temporal=(start_date, end_date),\n",
        "                    count=max_results * 2  # Get more results to filter later\n",
        "                )\n",
        "\n",
        "                print(f\"Found {len(results)} GEDI L1B granules (will filter spatially)\")\n",
        "                return results\n",
        "\n",
        "            except Exception as e3:\n",
        "                print(f\"All search attempts failed: {str(e3)}\")\n",
        "                return []\n",
        "\n",
        "# Extract and process data - Full Power beams only\n",
        "def extract_gedi_l1b_data(file_path, aoi_bbox, full_power_beams_only=True):\n",
        "    \"\"\"Extract GEDI L1B data with spatial filtering - Full Power beams only\"\"\"\n",
        "    extracted_data = {}\n",
        "\n",
        "    print(f\"\\nOpening GEDI file: {os.path.basename(file_path)}\")\n",
        "\n",
        "    try:\n",
        "        with h5py.File(file_path, 'r') as gedi_file:\n",
        "            # Get all beam names\n",
        "            all_beam_names = [key for key in gedi_file.keys() if key.startswith('BEAM')]\n",
        "\n",
        "            # Filter to Full Power beams only\n",
        "            if full_power_beams_only:\n",
        "                beam_names = [beam for beam in all_beam_names if beam in FULL_POWER_BEAMS]\n",
        "                print(f\"Available beams: {all_beam_names}\")\n",
        "                print(f\"Full Power beams found: {beam_names}\")\n",
        "            else:\n",
        "                beam_names = all_beam_names\n",
        "                print(f\"Available beams: {beam_names}\")\n",
        "\n",
        "            if not beam_names:\n",
        "                print(\"‚ùå No Full Power beams found in this file!\")\n",
        "                return {}\n",
        "\n",
        "            for beam in beam_names:\n",
        "                try:\n",
        "                    print(f\"\\n  Processing {beam}...\")\n",
        "\n",
        "                    # Check if required datasets exist\n",
        "                    required_datasets = [\n",
        "                        f'{beam}/geolocation/latitude_bin0',\n",
        "                        f'{beam}/geolocation/longitude_bin0',\n",
        "                        f'{beam}/shot_number',\n",
        "                        f'{beam}/geolocation/degrade',\n",
        "                        f'{beam}/stale_return_flag',\n",
        "                        f'{beam}/geolocation/elevation_bin0'\n",
        "                    ]\n",
        "\n",
        "                    missing_datasets = [ds for ds in required_datasets if ds not in gedi_file]\n",
        "                    if missing_datasets:\n",
        "                        print(f\"    ‚ö†Ô∏è Missing datasets: {missing_datasets}\")\n",
        "                        continue\n",
        "\n",
        "                    # Extract coordinate data\n",
        "                    # The GEDI elevation_bin0 dataset refers to the height above the World Geodetic System 1984 (WGS84) reference ellipsoid, as interpolated from a pre-existing digital elevation model (DEM).\n",
        "                    # This value provides a reference point for the ground elevation within a GEDI laser footprint.\n",
        "                    lat = gedi_file[f'{beam}/geolocation/latitude_bin0'][:]\n",
        "                    lon = gedi_file[f'{beam}/geolocation/longitude_bin0'][:]\n",
        "                    shot_number = gedi_file[f'{beam}/shot_number'][:]\n",
        "                    degrade_flag = gedi_file[f'{beam}/geolocation/degrade'][:]\n",
        "                    stale_return_flag = gedi_file[f'{beam}/stale_return_flag'][:]\n",
        "                    elev_bin0 = gedi_file[f'{beam}/geolocation/elevation_bin0'][:]\n",
        "\n",
        "                    print(f\"    Total shots in beam: {len(lat)}\")\n",
        "\n",
        "                    # Apply spatial filter\n",
        "                    spatial_mask = (\n",
        "                        (lon >= aoi_bbox[0]) & (lon <= aoi_bbox[2]) &\n",
        "                        (lat >= aoi_bbox[1]) & (lat <= aoi_bbox[3])\n",
        "                    )\n",
        "\n",
        "                    spatial_shots = np.sum(spatial_mask)\n",
        "                    print(f\"    Shots in AOI: {spatial_shots}\")\n",
        "\n",
        "                    if spatial_shots > 0:\n",
        "                        extracted_data[beam] = {\n",
        "                            'latitude': lat[spatial_mask],\n",
        "                            'longitude': lon[spatial_mask],\n",
        "                            'shot_number': shot_number[spatial_mask],\n",
        "                            'degrade_flag': degrade_flag[spatial_mask],\n",
        "                            'stale_return_flag': stale_return_flag[spatial_mask],\n",
        "                            'elevation_bin0': elev_bin0[spatial_mask]\n",
        "                        }\n",
        "                        print(f\"    ‚úì Extracted {spatial_shots} shots from {beam}\")\n",
        "                    else:\n",
        "                        print(f\"    ‚úó No shots found in AOI for {beam}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"    ‚ùå Error processing {beam}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        return extracted_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error opening file: {str(e)}\")\n",
        "        return {}\n",
        "\n",
        "# Apply quality filtering with detailed reporting\n",
        "def apply_quality_filters(gedi_data, verbose=True):\n",
        "    \"\"\"Apply standard GEDI quality filters with detailed reporting\"\"\"\n",
        "    if verbose:\n",
        "        print(f\"\\nApplying quality filters...\")\n",
        "        print(\"  Criteria: degrade_flag = 0, stale_return_flag = 0\")\n",
        "\n",
        "    filtered_data = {}\n",
        "    total_before = 0\n",
        "    total_after = 0\n",
        "\n",
        "    for beam, data in gedi_data.items():\n",
        "        if len(data['shot_number']) == 0:\n",
        "            continue\n",
        "\n",
        "        # Apply quality filters\n",
        "        quality_mask = (\n",
        "            (data['degrade_flag'] == 0) &\n",
        "            (data['stale_return_flag'] == 0)\n",
        "        )\n",
        "\n",
        "        shots_before = len(data['shot_number'])\n",
        "        shots_after = np.sum(quality_mask)\n",
        "        retention_rate = (shots_after / shots_before * 100) if shots_before > 0 else 0\n",
        "\n",
        "        total_before += shots_before\n",
        "        total_after += shots_after\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"  {beam}: {shots_before} ‚Üí {shots_after} shots ({retention_rate:.1f}% retained)\")\n",
        "\n",
        "        if shots_after > 0:\n",
        "            filtered_data[beam] = {\n",
        "                'latitude': data['latitude'][quality_mask],\n",
        "                'longitude': data['longitude'][quality_mask],\n",
        "                'shot_number': data['shot_number'][quality_mask],\n",
        "                'elevation_bin0': data['elevation_bin0'][quality_mask],\n",
        "                'degrade_flag': data['degrade_flag'][quality_mask],\n",
        "                'stale_return_flag': data['stale_return_flag'][quality_mask]\n",
        "            }\n",
        "\n",
        "    overall_retention = (total_after / total_before * 100) if total_before > 0 else 0\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nOverall: {total_before} ‚Üí {total_after} shots ({overall_retention:.1f}% retained)\")\n",
        "\n",
        "    return filtered_data, overall_retention, total_after\n",
        "\n",
        "def delete_file_safely(file_path):\n",
        "    \"\"\"Safely delete a file with confirmation\"\"\"\n",
        "    try:\n",
        "        if os.path.exists(file_path):\n",
        "            os.remove(file_path)\n",
        "            print(f\"üóëÔ∏è Deleted file: {os.path.basename(file_path)}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è File not found for deletion: {file_path}\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error deleting file {file_path}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def process_gedi_granules_with_retry(gedi_granules, aoi_bbox, is_default_aoi=False, max_attempts=None):\n",
        "    \"\"\"\n",
        "    Processa todos os granules encontrados, sem parar no primeiro com dados v√°lidos.\n",
        "    \"\"\"\n",
        "    download_dir = \"./gedi_data\"\n",
        "    os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "    processed_files = []\n",
        "    all_results = []\n",
        "\n",
        "    # If you don't specify max_attempts, it processes all.\n",
        "    if max_attempts is None:\n",
        "        max_attempts = len(gedi_granules)\n",
        "\n",
        "    for idx, granule in enumerate(gedi_granules[:max_attempts]):\n",
        "        try:\n",
        "            granule_id = granule['umm']['GranuleUR']\n",
        "        except:\n",
        "            granule_id = f\"Granule_{idx+1}\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"PROCESSANDO GRANULE {idx+1}/{len(gedi_granules)}: {granule_id}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Download\n",
        "        try:\n",
        "            downloaded_files = earthaccess.download([granule], local_path=download_dir)\n",
        "            if not downloaded_files:\n",
        "                print(f\"‚ùå Falha no download de {granule_id}\")\n",
        "                continue\n",
        "            sample_file = downloaded_files[0]\n",
        "            file_size = os.path.getsize(sample_file) / 1e9\n",
        "            print(f\"‚úì Baixado: {os.path.basename(sample_file)} ({file_size:.2f} GB)\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro no download de {granule_id}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Processing\n",
        "        gedi_data = extract_gedi_l1b_data(sample_file, aoi_bbox, full_power_beams_only=True)\n",
        "        if not gedi_data:\n",
        "            delete_file_safely(sample_file)\n",
        "            processed_files.append({'granule_id': granule_id, 'status': 'no_spatial_data'})\n",
        "            continue\n",
        "\n",
        "        filtered_data, retention_rate, shots_after_qa = apply_quality_filters(gedi_data)\n",
        "\n",
        "        total_shots_extracted = sum(len(v['shot_number']) for v in gedi_data.values())\n",
        "        processed_files.append({\n",
        "            'granule_id': granule_id,\n",
        "            'file_name': os.path.basename(sample_file),\n",
        "            'file_size_gb': file_size,\n",
        "            'shots_extracted': total_shots_extracted,\n",
        "            'shots_after_qa': shots_after_qa,\n",
        "            'retention_rate': retention_rate,\n",
        "            'status': 'success' if shots_after_qa > 0 else 'no_quality_data'\n",
        "        })\n",
        "\n",
        "        if shots_after_qa > 0:\n",
        "            # Add the data to the complete set\n",
        "            for beam, data in filtered_data.items():\n",
        "                df = pd.DataFrame({\n",
        "                    'granule_id': granule_id,\n",
        "                    'beam': beam,\n",
        "                    'shot_number': data['shot_number'],\n",
        "                    'latitude': data['latitude'],\n",
        "                    'longitude': data['longitude'],\n",
        "                    'elevation_bin0': data['elevation_bin0']\n",
        "                })\n",
        "                all_results.append(df)\n",
        "\n",
        "        else:\n",
        "            delete_file_safely(sample_file)\n",
        "\n",
        "    # Concatenates all results\n",
        "    if all_results:\n",
        "        result_df = pd.concat(all_results, ignore_index=True)\n",
        "        print(f\"\\nüéâ Processamento completo: {len(result_df)} disparos de alta qualidade extra√≠dos!\")\n",
        "        success = True\n",
        "    else:\n",
        "        print(f\"\\n‚ùå Nenhum granule teve dados de qualidade.\")\n",
        "        result_df = None\n",
        "        success = False\n",
        "\n",
        "    return success, result_df, processed_files, None\n",
        "\n",
        "# Perform the search\n",
        "print(f\"\\nüîç Searching for GEDI L1B granules...\")\n",
        "gedi_granules = search_gedi_l1b(aoi_bbox, start_date, end_date, max_results=2000)##40\n",
        "\n",
        "if gedi_granules:\n",
        "    print(f\"\\nüìã Found granules:\")\n",
        "    for i, granule in enumerate(gedi_granules[:2]):  # Show first 5\n",
        "        try:\n",
        "            granule_id = granule['umm']['GranuleUR']\n",
        "            demo_note = \" (‚Üê DEMO PRIORITY)\" if is_default_aoi and i == 1 else \"\"\n",
        "            print(f\"  {i+1}. {granule_id}{demo_note}\")\n",
        "        except:\n",
        "            print(f\"  {i+1}. Granule found (ID extraction failed)\")\n",
        "\n",
        "    if len(gedi_granules) > 2:\n",
        "        print(f\"  ... and {len(gedi_granules) - 2} more granules\")\n",
        "\n",
        "    # Process granules with automatic retry (and demo optimization if applicable)\n",
        "    print(f\"\\nüöÄ Starting processing with automatic retry...\")\n",
        "    success, result_df, processing_log, final_file = process_gedi_granules_with_retry(\n",
        "    gedi_granules, aoi_bbox, is_default_aoi=is_default_aoi, max_attempts=len(gedi_granules)\n",
        ")\n",
        "\n",
        "    # Display processing summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"PROCESSING SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    processing_df = pd.DataFrame(processing_log)\n",
        "    if not processing_df.empty:\n",
        "        print(f\"\\nFiles processed:\")\n",
        "        for _, row in processing_df.iterrows():\n",
        "            status_icon = {\n",
        "                'success': '‚úÖ',\n",
        "                'no_spatial_data': 'üö´',\n",
        "                'no_quality_data': '‚ùå',\n",
        "                'processed': 'üìä'\n",
        "            }.get(row['status'], '‚ùì')\n",
        "\n",
        "            print(f\"  {status_icon} {row['file_name']} ({row['file_size_gb']:.2f} GB)\")\n",
        "            print(f\"      Status: {row['status']}\")\n",
        "            print(f\"      Shots extracted: {row['shots_extracted']}\")\n",
        "            print(f\"      Shots after QA: {row['shots_after_qa']}\")\n",
        "            print(f\"      Retention rate: {row['retention_rate']:.1f}%\")\n",
        "\n",
        "    if success and result_df is not None:\n",
        "        print(f\"\\nüéâ FINAL RESULTS:\")\n",
        "        print(f\"  ‚úÖ Successfully processed granule with quality data\")\n",
        "        print(f\"  üìä Total high-quality shots: {len(result_df)}\")\n",
        "        print(f\"  üéØ Full Power beams processed: {result_df['beam'].nunique()}\")\n",
        "\n",
        "        # Display sample data\n",
        "        print(f\"\\nüìã Sample of processed data:\")\n",
        "        print(result_df.head(10))\n",
        "\n",
        "        print(f\"\\nüìà Data summary:\")\n",
        "        print(f\"  Beams processed: {result_df['beam'].nunique()}\")\n",
        "        print(f\"  Shots per beam: {result_df.groupby('beam').size().to_dict()}\")\n",
        "        print(f\"  Elevation range: {result_df['elevation_bin0'].min():.1f} to {result_df['elevation_bin0'].max():.1f} m\")\n",
        "        print(f\"  Latitude range: {result_df['latitude'].min():.6f} to {result_df['latitude'].max():.6f}\")\n",
        "        print(f\"  Longitude range: {result_df['longitude'].min():.6f} to {result_df['longitude'].max():.6f}\")\n",
        "\n",
        "        # Export results\n",
        "        output_dir = \"./gedi_L1B_outputs\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Export main results\n",
        "        csv_path = os.path.join(output_dir, \"gedi_l1b_quality_filtered_full_power.csv\")\n",
        "        result_df.to_csv(csv_path, index=False)\n",
        "        print(f\"\\nüíæ Results exported to: {csv_path}\")\n",
        "\n",
        "        # Export processing log\n",
        "        log_path = os.path.join(output_dir, \"processing_log.csv\")\n",
        "        processing_df.to_csv(log_path, index=False)\n",
        "        print(f\"üíæ Processing log exported to: {log_path}\")\n",
        "\n",
        "        # Create visualization\n",
        "        print(f\"\\nüìä Creating visualizations...\")\n",
        "        plt.figure(figsize=(16, 10))\n",
        "\n",
        "        # Create subplot layout\n",
        "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        # Plot 1: Shot locations colored by elevation\n",
        "        scatter = ax1.scatter(result_df['longitude'], result_df['latitude'],\n",
        "                            c=result_df['elevation_bin0'], cmap='terrain', s=30, alpha=0.7)\n",
        "        ax1.set_xlabel('Longitude')\n",
        "        ax1.set_ylabel('Latitude')\n",
        "        ax1.set_title('GEDI L1B High-Quality Shots (Full Power Beams)')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        plt.colorbar(scatter, ax=ax1, label='Elevation (m)')\n",
        "\n",
        "        # Plot 2: Elevation histogram\n",
        "        ax2.hist(result_df['elevation_bin0'], bins=30, alpha=0.7, edgecolor='black')\n",
        "        ax2.set_xlabel('Elevation (m)')\n",
        "        ax2.set_ylabel('Number of Shots')\n",
        "        ax2.set_title('Elevation Distribution')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        # Plot 3: Shots per beam\n",
        "        beam_counts = result_df['beam'].value_counts()\n",
        "        ax3.bar(beam_counts.index, beam_counts.values, alpha=0.7)\n",
        "        ax3.set_xlabel('Beam')\n",
        "        ax3.set_ylabel('Number of Shots')\n",
        "        ax3.set_title('Shots per Full Power Beam')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "        plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45)\n",
        "\n",
        "        # Plot 4: Processing attempts\n",
        "        status_counts = processing_df['status'].value_counts()\n",
        "        ax4.pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%')\n",
        "        ax4.set_title('Processing Results')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Create interactive map\n",
        "        print(f\"\\nüó∫Ô∏è Creating interactive map...\")\n",
        "        center_lat = result_df['latitude'].mean()\n",
        "        center_lon = result_df['longitude'].mean()\n",
        "\n",
        "        m = folium.Map(location=[center_lat, center_lon], zoom_start=13)\n",
        "\n",
        "        # Add AOI rectangle\n",
        "        folium.Rectangle(\n",
        "            bounds=[[aoi_bbox[1], aoi_bbox[0]], [aoi_bbox[3], aoi_bbox[2]]],\n",
        "            fill=False,\n",
        "            color='red',\n",
        "            weight=3,\n",
        "            popup='Area of Interest'\n",
        "        ).add_to(m)\n",
        "\n",
        "        # Color map for different beams\n",
        "        beam_colors = {'BEAM0101': 'red', 'BEAM0110': 'blue', 'BEAM1000': 'green', 'BEAM1011': 'orange'}\n",
        "\n",
        "        # Add points colored by beam\n",
        "        for _, row in result_df.iterrows():\n",
        "            color = beam_colors.get(row['beam'], 'gray')\n",
        "            folium.CircleMarker(\n",
        "                location=[row['latitude'], row['longitude']],\n",
        "                radius=4,\n",
        "                popup=f\"Beam: {row['beam']}<br>Shot: {row['shot_number']}<br>Elevation: {row['elevation_bin0']:.1f}m\",\n",
        "                color=color,\n",
        "                fillColor=color,\n",
        "                fillOpacity=0.7\n",
        "            ).add_to(m)\n",
        "\n",
        "        # Add legend\n",
        "        legend_html = '''\n",
        "        <div style=\"position: fixed;\n",
        "                    bottom: 50px; left: 50px; width: 150px; height: 90px;\n",
        "                    background-color: white; border:2px solid grey; z-index:9999;\n",
        "                    font-size:14px; padding: 10px\">\n",
        "        <p><b>Full Power Beams</b></p>\n",
        "        <p><i class=\"fa fa-circle\" style=\"color:red\"></i> BEAM0101</p>\n",
        "        <p><i class=\"fa fa-circle\" style=\"color:blue\"></i> BEAM0110</p>\n",
        "        <p><i class=\"fa fa-circle\" style=\"color:green\"></i> BEAM1000</p>\n",
        "        <p><i class=\"fa fa-circle\" style=\"color:orange\"></i> BEAM1011</p>\n",
        "        </div>\n",
        "        '''\n",
        "        m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "        # Display map\n",
        "        m\n",
        "\n",
        "    else:\n",
        "        print(f\"\\n‚ùå PROCESSING FAILED:\")\n",
        "        print(f\"  No granules contained quality data in the AOI\")\n",
        "        print(f\"  Files attempted: {len(processing_log)}\")\n",
        "        print(f\"\\nüí° Suggestions:\")\n",
        "        print(f\"    - Expand your AOI bounding box\")\n",
        "        print(f\"    - Try a different time period\")\n",
        "        print(f\"    - Check if your AOI is in a valid GEDI coverage area (¬±51.6¬∞ latitude)\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No granules found. Try expanding your search criteria.\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"PROCESSING COMPLETE\")\n",
        "print(f\"{'='*80}\")\n",
        "print(\"‚úÖ Data search completed\")\n",
        "print(\"‚úÖ Full Power beams processing only\")\n",
        "print(\"‚úÖ Automatic retry for quality data\")\n",
        "if is_default_aoi:\n",
        "    print(\"‚úÖ Demo optimization enabled (5th granule prioritized)\")\n",
        "print(\"‚úÖ File cleanup for unusable data\")\n",
        "print(\"‚úÖ Results exported\")\n",
        "print(\"\\nüîß Next steps:\")\n",
        "print(\"   - Modify aoi_bbox for your study area\")\n",
        "print(\"   - Adjust quality filtering criteria if needed\")\n",
        "print(\"   - Add waveform analysis functions\")\n",
        "print(\"   - Process additional granules if needed\")\n",
        "print(\"\\nüìÅ Output files saved to: ./gedi_L1B_outputs/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "- Set or verify that the directory path is correct.\n",
        "\n",
        "- Enter the latitude and longitude with five decimal places. To obtain the lat/long values, it is necessary to download and visualize the GEDI data in a GIS. This will allow you to determine whether the waveform falls within your sample area.\n",
        "\n",
        "\n",
        "This code extracts the waveforms using latitude and longitude."
      ],
      "metadata": {
        "id": "GT3ztUK8q6XR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####### Code runs by using coordinates ##\n",
        "\n",
        "from time import sleep\n",
        "import gc\n",
        "\n",
        "# ================= Set up ===================\n",
        "gedi_dir = \"/content/gedi_data\"\n",
        "output_dir = \"/content/waveform_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "show_plots = True\n",
        "pause_time = 1\n",
        "tol = 1e-5  # tolerance in degrees (~1 m)\n",
        "\n",
        "# üëâ Specific coordinates (set manually or use input)\n",
        "latitude = float(input(\"Enter the desired latitude (5 decimal places): \"))\n",
        "longitude = float(input(\"Enter the desired longitude (5 decimal places): \"))\n",
        "\n",
        "# ===================================================\n",
        "\n",
        "def process_waveform(beam, shot, f, file_name, output_dir):\n",
        "    \"\"\"Extracts and saves the 1 waveform graph\"\"\"\n",
        "    try:\n",
        "        if f\"{beam}/shot_number\" not in f:\n",
        "            return False\n",
        "\n",
        "        shot_numbers = f[f\"{beam}/shot_number\"][:]\n",
        "        idx = np.where(shot_numbers == shot)[0]\n",
        "        if len(idx) == 0:\n",
        "            return False\n",
        "        idx = idx[0]\n",
        "\n",
        "        wf_full = f[f\"{beam}/rxwaveform\"][:]\n",
        "        start = f[f\"{beam}/rx_sample_start_index\"][idx]\n",
        "        count = f[f\"{beam}/rx_sample_count\"][idx]\n",
        "\n",
        "        elev0 = f[f\"{beam}/geolocation/elevation_bin0\"][idx]\n",
        "        elev_last = f[f\"{beam}/geolocation/elevation_lastbin\"][idx]\n",
        "        lat = f[f\"{beam}/geolocation/latitude_bin0\"][idx]\n",
        "        lon = f[f\"{beam}/geolocation/longitude_bin0\"][idx]\n",
        "\n",
        "        waveform = wf_full[start:start+count]\n",
        "        elevations = np.linspace(elev0, elev_last, len(waveform))\n",
        "\n",
        "        # Point of maximum amplitude\n",
        "        max_amp_idx = np.argmax(waveform)\n",
        "        max_amp_elevation = elevations[max_amp_idx]\n",
        "        max_amp_value = waveform[max_amp_idx]\n",
        "\n",
        "        plt.figure(figsize=(8, 10))\n",
        "        plt.plot(waveform, elevations, 'b', linewidth=2, label='Waveform')\n",
        "        plt.scatter(max_amp_value, max_amp_elevation, color='red', s=50, label=f'Max Amp: {max_amp_elevation:.1f}m')\n",
        "        plt.axhline(y=elev0, color='r', linestyle='--', label=f'Top: {elev0:.1f}m')\n",
        "        plt.axhline(y=elev_last, color='g', linestyle='--', label=f'Bottom: {elev_last:.1f}m')\n",
        "        plt.xlabel(\"Waveform Amplitude\", fontsize=12)\n",
        "        plt.ylabel(\"Elevation (m)\", fontsize=12)\n",
        "        plt.title(f\"Shot {shot} - {beam}\\nLat: {lat:.5f}, Lon: {lon:.5f}\\nFile: {file_name}\", fontsize=13)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(output_dir, f\"{beam}_{shot}.png\")\n",
        "        plt.savefig(save_path, dpi=200, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"üíæ Saved {save_path}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {beam}-{shot}: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def process_gedi_by_coord(gedi_dir, lat_alvo, lon_alvo, output_dir, tol=1e-5):\n",
        "    \"\"\"Search and extract waveforms for a specific latitude/longitude.\"\"\"\n",
        "    total_found = 0\n",
        "    files = [os.path.join(gedi_dir, f) for f in os.listdir(gedi_dir) if f.endswith('.h5')]\n",
        "\n",
        "    for file_path in files:\n",
        "        try:\n",
        "            with h5py.File(file_path, 'r') as f:\n",
        "                available_beams = list(f.keys())\n",
        "                print(f\"üîç Checking {os.path.basename(file_path)} ({len(available_beams)} beams)\")\n",
        "\n",
        "                for beam in available_beams:\n",
        "                    if not (f\"{beam}/geolocation/latitude_bin0\" in f):\n",
        "                        continue\n",
        "\n",
        "                    lat_all = f[f\"{beam}/geolocation/latitude_bin0\"][:]\n",
        "                    lon_all = f[f\"{beam}/geolocation/longitude_bin0\"][:]\n",
        "                    shots_all = f[f\"{beam}/shot_number\"][:]\n",
        "\n",
        "                    # Find coordinates within tolerance.\n",
        "                    idx = np.where(\n",
        "                        (np.abs(lat_all - lat_alvo) <= tol) &\n",
        "                        (np.abs(lon_all - lon_alvo) <= tol)\n",
        "                    )[0]\n",
        "\n",
        "                    if len(idx) > 0:\n",
        "                        shot = shots_all[idx[0]]\n",
        "                        print(f\"‚úÖ Found in {os.path.basename(file_path)} ‚Äî {beam}, shot {shot}\")\n",
        "                        ok = process_waveform(beam, shot, f,\n",
        "                                              os.path.basename(file_path), output_dir)\n",
        "                        if ok:\n",
        "                            total_found += 1\n",
        "                            if show_plots:\n",
        "                                plt.show()\n",
        "                                sleep(pause_time)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error reading {os.path.basename(file_path)}: {e}\")\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    print(f\"\\nüéØ Total number of waveforms extracted and saved: {total_found}\")\n",
        "\n",
        "\n",
        "# ================= Performance ===================\n",
        "process_gedi_by_coord(\n",
        "    gedi_dir=gedi_dir,\n",
        "    lat_alvo=latitude,\n",
        "    lon_alvo=longitude,\n",
        "    output_dir=output_dir,\n",
        "    tol=tol\n",
        ")\n"
      ],
      "metadata": {
        "id": "QJ_2Rc69wwMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "- Set or verify that the directory path is correct.\n",
        "\n",
        "- Provide a CSV file containing the selected waveforms along with latitude, longitude, and class columns. To obtain the latitude and longitude values, the GEDI data must be downloaded and visualized in a GIS environment. This procedure allows verification of whether each waveform falls within the defined sample area.\n",
        "\n",
        "\n",
        "This code extracts the waveforms a csv file."
      ],
      "metadata": {
        "id": "_Ix4NsevrwHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####### Code runs by using a csv file ##\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import gc\n",
        "\n",
        "# ================= PARAMETERS ====================\n",
        "gedi_dir = \"/content/gedi_data\"\n",
        "csv_path = \"/content/points/GEDI_L1B_Medicilandia_reduced.csv\"\n",
        "output_dir = \"/content/waveform_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "tol = 1e-5  # tolerance\n",
        "# =================================================\n",
        "\n",
        "\n",
        "def find_shot_by_coord_stream(f, beam, lat_alvo, lon_alvo, tol, chunk=20000):\n",
        "    \"\"\"\n",
        "    Coordinate search without loading full arrays\n",
        "    Reading latitude and longitude in smaller chunks\n",
        "    \"\"\"\n",
        "    lat_ds = f[f\"{beam}/geolocation/latitude_bin0\"]\n",
        "    lon_ds = f[f\"{beam}/geolocation/longitude_bin0\"]\n",
        "    shot_ds = f[f\"{beam}/shot_number\"]\n",
        "\n",
        "    total = lat_ds.shape[0]\n",
        "\n",
        "    for i in range(0, total, chunk):\n",
        "        end = min(i + chunk, total)\n",
        "        lat = lat_ds[i:end]\n",
        "        lon = lon_ds[i:end]\n",
        "\n",
        "        idx = np.where(\n",
        "            (np.abs(lat - lat_alvo) <= tol) &\n",
        "            (np.abs(lon - lon_alvo) <= tol)\n",
        "        )[0]\n",
        "\n",
        "        if len(idx) > 0:\n",
        "            return int(shot_ds[i + idx[0]])\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_waveform_minimal(f, beam, shot):\n",
        "    \"\"\"\n",
        "    Extracts only the target shot waveform without loading the full rxwaveform dataset\n",
        "    \"\"\"\n",
        "    # Finds the shot index\n",
        "    shots = f[f\"{beam}/shot_number\"]\n",
        "\n",
        "    # Search using blocks\n",
        "    for i in range(0, shots.shape[0], 20000):\n",
        "        end = min(i + 20000, shots.shape[0])\n",
        "        block = shots[i:end]\n",
        "        idx = np.where(block == shot)[0]\n",
        "        if len(idx) > 0:\n",
        "            idx = i + idx[0]\n",
        "            break\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    # Retrieves metadata.\n",
        "    start = int(f[f\"{beam}/rx_sample_start_index\"][idx])\n",
        "    count = int(f[f\"{beam}/rx_sample_count\"][idx])\n",
        "\n",
        "    elev0 = float(f[f\"{beam}/geolocation/elevation_bin0\"][idx])\n",
        "    elev_last = float(f[f\"{beam}/geolocation/elevation_lastbin\"][idx])\n",
        "\n",
        "    # l√™ somente o intervalo necess√°rio\n",
        "    rx = f[f\"{beam}/rxwaveform\"]\n",
        "    waveform = rx[start:start+count]\n",
        "\n",
        "    elevations = np.linspace(elev0, elev_last, len(waveform))\n",
        "\n",
        "    return waveform, elevations\n",
        "\n",
        "\n",
        "def process(csv_path, gedi_dir, output_dir, tol):\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Open one figure per class\n",
        "    figs = {}\n",
        "    axes = {}\n",
        "\n",
        "    files = [os.path.join(gedi_dir, x) for x in os.listdir(gedi_dir) if x.endswith(\".h5\")]\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        lat, lon, class = row[\"latitude\"], row[\"longitude\"], row[\"class\"]\n",
        "        print(f\"\\nüîç Ponto {idx+1}: class {class} ({lat}, {lon})\")\n",
        "\n",
        "        if class not in figs:\n",
        "            figs[class], axes[class] = plt.subplots(figsize=(7, 10))\n",
        "\n",
        "        ax = axes[class]\n",
        "\n",
        "        found = False\n",
        "\n",
        "        for fp in files:\n",
        "            with h5py.File(fp, \"r\") as f:\n",
        "                for beam in f.keys():\n",
        "                    if f\"{beam}/geolocation/latitude_bin0\" not in f:\n",
        "                        continue\n",
        "\n",
        "                    shot = find_shot_by_coord_stream(f, beam, lat, lon, tol)\n",
        "\n",
        "                    if shot is None:\n",
        "                        continue\n",
        "\n",
        "                    print(f\"‚úî Encontrado: {os.path.basename(fp)} ‚Üí {beam}, shot {shot}\")\n",
        "\n",
        "                    result = extract_waveform_minimal(f, beam, shot)\n",
        "                    if result is None:\n",
        "                        continue\n",
        "\n",
        "                    wf, elev = result\n",
        "\n",
        "                    # Add curve directly to the plot without keeping it in memory\n",
        "                    ax.plot(wf, elev, linewidth=0.8)\n",
        "\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if found:\n",
        "                break\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    # Save all plots\n",
        "    print(\"\\nüìä Salvando imagens...\")\n",
        "    for class, fig in figs.items():\n",
        "        ax = axes[class]\n",
        "        ax.set_xlabel(\"Amplitude\")\n",
        "        ax.set_ylabel(\"Eleva√ß√£o (m)\")\n",
        "        ax.set_title(f\"Waveforms da class {class}\")\n",
        "        ax.grid(alpha=0.3)\n",
        "\n",
        "        fig.tight_layout()\n",
        "        save_path = os.path.join(output_dir, f\"class_{class}.png\")\n",
        "        fig.savefig(save_path, dpi=200)\n",
        "        plt.close(fig)\n",
        "        print(f\"  üíæ {save_path}\")\n",
        "\n",
        "    print(\"\\nüèÅ Finalizado com uso m√≠nimo de mem√≥ria!\\n\")\n",
        "\n",
        "\n",
        "# execute\n",
        "process(csv_path, gedi_dir, output_dir, tol)"
      ],
      "metadata": {
        "id": "vRJAU7uMVv24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "- Set or verify that the directory path is correct.\n",
        "\n",
        "- Provide a CSV file containing the selected waveforms along with latitude, longitude, and class columns. To obtain the latitude and longitude values, the GEDI data must be downloaded and visualized in a GIS environment. This procedure allows verification of whether each waveform falls within the defined sample area.\n",
        "\n",
        "\n",
        "This code extracts the waveforms a csv file, creating a mean and std graph ."
      ],
      "metadata": {
        "id": "w4HE6vtstL2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Code runs by using csv, creating a mean and std graph ##\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import gc\n",
        "\n",
        "# ================= PARAMETERS ====================\n",
        "#.csv needs latitude, longitude, class\n",
        "gedi_dir = \"/content/gedi_data\"\n",
        "csv_path = \"/content/points/GEDI_L1B_Medicilandia_samples.csv\"\n",
        "output_dir = \"/content/waveform_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "tol = 1e-5\n",
        "N_GRID = 400  # Common elevation grid\n",
        "# =================================================\n",
        "\n",
        "\n",
        "def find_shot_by_coord_stream(f, beam, lat_alvo, lon_alvo, tol, chunk=20000):\n",
        "    lat = f[f\"{beam}/geolocation/latitude_bin0\"]\n",
        "    lon = f[f\"{beam}/geolocation/longitude_bin0\"]\n",
        "    shots = f[f\"{beam}/shot_number\"]\n",
        "\n",
        "    total = len(lat)\n",
        "\n",
        "    for i in range(0, total, chunk):\n",
        "        end = min(i + chunk, total)\n",
        "        block_lat = lat[i:end]\n",
        "        block_lon = lon[i:end]\n",
        "\n",
        "        idx = np.where(\n",
        "            (np.abs(block_lat - lat_alvo) <= tol) &\n",
        "            (np.abs(block_lon - lon_alvo) <= tol)\n",
        "        )[0]\n",
        "\n",
        "        if len(idx) > 0:\n",
        "            return int(shots[i + idx[0]])\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_waveform_minimal(f, beam, shot):\n",
        "    shots = f[f\"{beam}/shot_number\"]\n",
        "\n",
        "    # Sequential search\n",
        "    for i in range(0, shots.shape[0], 20000):\n",
        "        end = min(i + 20000, shots.shape[0])\n",
        "        block = shots[i:end]\n",
        "        idx = np.where(block == shot)[0]\n",
        "        if len(idx):\n",
        "            idx = i + idx[0]\n",
        "            break\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    start = int(f[f\"{beam}/rx_sample_start_index\"][idx])\n",
        "    count = int(f[f\"{beam}/rx_sample_count\"][idx])\n",
        "\n",
        "    elev0 = float(f[f\"{beam}/geolocation/elevation_bin0\"][idx])\n",
        "    elev_last = float(f[f\"{beam}/geolocation/elevation_lastbin\"][idx])\n",
        "\n",
        "    waveform = f[f\"{beam}/rxwaveform\"][start:start + count]\n",
        "    elevations = np.linspace(elev0, elev_last, len(waveform))\n",
        "\n",
        "    return waveform, elevations\n",
        "\n",
        "\n",
        "def process(csv_path, gedi_dir, output_dir, tol):\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    class_waveforms = {}   # Stores resampled curves\n",
        "    class_elev_grids = {}  # Uniform Y-axis\n",
        "\n",
        "    files = [os.path.join(gedi_dir, f) for f in os.listdir(gedi_dir) if f.endswith(\".h5\")]\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        lat, lon, class = row[\"latitude\"], row[\"longitude\"], row[\"class\"]\n",
        "        print(f\"\\nüîç Procurando: class {class}, ponto {idx+1}\")\n",
        "\n",
        "        if class not in class_waveforms:\n",
        "            class_waveforms[class] = []\n",
        "            class_elev_grids[class] = None\n",
        "\n",
        "        found = False\n",
        "\n",
        "        for fp in files:\n",
        "            with h5py.File(fp, \"r\") as f:\n",
        "\n",
        "                for beam in f.keys():\n",
        "                    if f\"{beam}/geolocation/latitude_bin0\" not in f:\n",
        "                        continue\n",
        "\n",
        "                    shot = find_shot_by_coord_stream(f, beam, lat, lon, tol)\n",
        "                    if not shot:\n",
        "                        continue\n",
        "\n",
        "                    print(f\"‚úî Encontrado em {fp} ‚Üí {beam}, shot {shot}\")\n",
        "\n",
        "                    result = extract_waveform_minimal(f, beam, shot)\n",
        "                    if not result:\n",
        "                        continue\n",
        "\n",
        "                    wf, elev = result\n",
        "\n",
        "                    # Creates a fixed grid similar to the wavelength in R\n",
        "                    if class_elev_grids[class] is None:\n",
        "                        class_elev_grids[class] = np.linspace(\n",
        "                            max(elev), min(elev), N_GRID\n",
        "                        )\n",
        "\n",
        "                    elev_grid = class_elev_grids[class]\n",
        "\n",
        "                    wf_interp = np.interp(elev_grid, elev[::-1], wf[::-1])\n",
        "                    class_waveforms[class].append(wf_interp)\n",
        "\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if found:\n",
        "                break\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "    # ====================================================\n",
        "    #            FINAL: PLOT MEAN + DEVIATION\n",
        "    # ====================================================\n",
        "    for class in class_waveforms.keys():\n",
        "\n",
        "        wave_list = class_waveforms[class]\n",
        "        elev_grid = class_elev_grids[class]\n",
        "\n",
        "        if len(wave_list) == 0:\n",
        "            continue\n",
        "\n",
        "        n_waveforms = len(wave_list)   # <<< Number of waveforms\n",
        "\n",
        "        arr = np.vstack(wave_list)\n",
        "        mean_curve = arr.mean(axis=0)\n",
        "        std_curve = arr.std(axis=0)\n",
        "\n",
        "        plt.figure(figsize=(10, 12))\n",
        "\n",
        "        # ribbon (deviation area)\n",
        "        plt.fill_betweenx(\n",
        "            elev_grid,\n",
        "            mean_curve - std_curve,\n",
        "            mean_curve + std_curve,\n",
        "            color=\"cornflowerblue\",\n",
        "            alpha=0.25,\n",
        "            label=\"Standard Deviation\"\n",
        "        )\n",
        "\n",
        "        # mean line\n",
        "        plt.plot(mean_curve, elev_grid, color=\"blue\", linewidth=2.5, label=\"Mean\")\n",
        "\n",
        "        # keep original direction\n",
        "        plt.xlabel(\"Waveform Amplitude\", fontsize=12,fontweight=\"bold\")\n",
        "        plt.ylabel(\"Elevation (m)\", fontsize=12, fontweight=\"bold\")\n",
        "        plt.title(f\"Waveform ‚Äì {class}\", fontsize=14,fontweight=\"bold\")\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.legend()\n",
        "\n",
        "        # Fixe vertical scale between -20 and 80 m\n",
        "        plt.ylim(-20, 60)\n",
        "        plt.xlim(0, 700)\n",
        "\n",
        "        # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "        # Insert text with number of waveforms\n",
        "        plt.text(\n",
        "            0.02, 0.95,\n",
        "            f\"Number of Waveforms: {n_waveforms}\",\n",
        "            transform=plt.gca().transAxes,\n",
        "            fontsize=12,\n",
        "            verticalalignment='top',\n",
        "            bbox=dict(facecolor='white', alpha=0.6, edgecolor='none')\n",
        "        )\n",
        "        # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(output_dir, f\"{class}_media_desvio.png\")\n",
        "        plt.savefig(save_path, dpi=250)\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"üíæ Salvo: {save_path}\")\n",
        "\n",
        "\n",
        "# execute\n",
        "process(csv_path, gedi_dir, output_dir, tol)\n"
      ],
      "metadata": {
        "id": "P0WWKIfgaW5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "- Set or verify that the directory path is correct.\n",
        "\n",
        "- Provide a CSV file containing the selected waveforms along with latitude, longitude, and class columns. To obtain the latitude and longitude values, the GEDI data must be downloaded and visualized in a GIS environment. This procedure allows verification of whether each waveform falls within the defined sample area.\n",
        "\n",
        "\n",
        "This code extracts the waveforms a csv file, creating a mean and std graph with robust outlier removal."
      ],
      "metadata": {
        "id": "TwjthTfWtmGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================== ENHANCED: Comparison of waveforms and robust outlier removal ========================\n",
        "# keep the structure, just adding better methods to compare waveforms.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import gc\n",
        "\n",
        "# ================= PARAMETERS ====================\n",
        "gedi_dir = \"/content/gedi_data\"\n",
        "csv_path = \"/content/points/culturas_perenes_amostras.csv\"\n",
        "output_dir = \"/content/waveform_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "tol = 1e-5\n",
        "N_GRID = 400\n",
        "# =================================================\n",
        "\n",
        "\n",
        "def find_shot_by_coord_stream(f, beam, lat_alvo, lon_alvo, tol, chunk=20000):\n",
        "    lat = f[f\"{beam}/geolocation/latitude_bin0\"]\n",
        "    lon = f[f\"{beam}/geolocation/longitude_bin0\"]\n",
        "    shots = f[f\"{beam}/shot_number\"]\n",
        "\n",
        "    total = len(lat)\n",
        "    for i in range(0, total, chunk):\n",
        "        end = min(i + chunk, total)\n",
        "        block_lat = lat[i:end]\n",
        "        block_lon = lon[i:end]\n",
        "\n",
        "        idx = np.where(\n",
        "            (np.abs(block_lat - lat_alvo) <= tol) &\n",
        "            (np.abs(block_lon - lon_alvo) <= tol)\n",
        "        )[0]\n",
        "\n",
        "        if len(idx) > 0:\n",
        "            return int(shots[i + idx[0]])\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_waveform_minimal(f, beam, shot):\n",
        "    shots = f[f\"{beam}/shot_number\"]\n",
        "\n",
        "    for i in range(0, shots.shape[0], 20000):\n",
        "        end = min(i + 20000, shots.shape[0])\n",
        "        block = shots[i:end]\n",
        "        idx = np.where(block == shot)[0]\n",
        "        if len(idx):\n",
        "            idx = i + idx[0]\n",
        "            break\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    start = int(f[f\"{beam}/rx_sample_start_index\"][idx])\n",
        "    count = int(f[f\"{beam}/rx_sample_count\"][idx])\n",
        "\n",
        "    elev0 = float(f[f\"{beam}/geolocation/elevation_bin0\"][idx])\n",
        "    elev_last = float(f[f\"{beam}/geolocation/elevation_lastbin\"][idx])\n",
        "\n",
        "    waveform = f[f\"{beam}/rxwaveform\"][start:start + count]\n",
        "    elevations = np.linspace(elev0, elev_last, len(waveform))\n",
        "\n",
        "    return waveform, elevations\n",
        "\n",
        "\n",
        "def rms_distance(a, b):\n",
        "    \"\"\"Dist√¢ncia RMS entre dois vetores.\"\"\"\n",
        "    return np.sqrt(np.mean((a - b) ** 2))\n",
        "\n",
        "\n",
        "def process(csv_path, gedi_dir, output_dir, tol):\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    class_waveforms = {}\n",
        "    class_elev_grids = {}\n",
        "\n",
        "    files = [os.path.join(gedi_dir, f) for f in os.listdir(gedi_dir) if f.endswith(\".h5\")]\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        lat, lon, class = row[\"latitude\"], row[\"longitude\"], row[\"class\"]\n",
        "        print(f\"\\nüîç Procurando: class {class}, ponto {idx+1}\")\n",
        "\n",
        "        if class not in class_waveforms:\n",
        "            class_waveforms[class] = []\n",
        "            class_elev_grids[class] = None\n",
        "\n",
        "        found = False\n",
        "\n",
        "        for fp in files:\n",
        "            with h5py.File(fp, \"r\") as f:\n",
        "\n",
        "                for beam in f.keys():\n",
        "                    if f\"{beam}/geolocation/latitude_bin0\" not in f:\n",
        "                        continue\n",
        "\n",
        "                    shot = find_shot_by_coord_stream(f, beam, lat, lon, tol)\n",
        "                    if not shot:\n",
        "                        continue\n",
        "\n",
        "                    print(f\"‚úî Encontrado em {fp} ‚Üí {beam}, shot {shot}\")\n",
        "\n",
        "                    result = extract_waveform_minimal(f, beam, shot)\n",
        "                    if not result:\n",
        "                        continue\n",
        "\n",
        "                    wf, elev = result\n",
        "\n",
        "                    if class_elev_grids[class] is None:\n",
        "                        class_elev_grids[class] = np.linspace(max(elev), min(elev), N_GRID)\n",
        "\n",
        "                    elev_grid = class_elev_grids[class]\n",
        "                    wf_interp = np.interp(elev_grid, elev[::-1], wf[::-1])\n",
        "                    class_waveforms[class].append(wf_interp)\n",
        "\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if found:\n",
        "                break\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    # ====================================================\n",
        "    #            COMPARISON AND REMOTION OF OUTLIERS\n",
        "    # ====================================================\n",
        "    for class in class_waveforms.keys():\n",
        "\n",
        "        wave_list = class_waveforms[class]\n",
        "        elev_grid = class_elev_grids[class]\n",
        "\n",
        "        if len(wave_list) == 0:\n",
        "            continue\n",
        "\n",
        "        arr = np.vstack(wave_list)\n",
        "\n",
        "        prelim_mean = arr.mean(axis=0)\n",
        "\n",
        "        distances = np.array([rms_distance(w, prelim_mean) for w in arr])\n",
        "\n",
        "        mean_dist = distances.mean()\n",
        "        std_dist = distances.std()\n",
        "\n",
        "        threshold = mean_dist + 3 * std_dist\n",
        "\n",
        "        mask = distances <= threshold\n",
        "        arr_clean = arr[mask]\n",
        "\n",
        "        removed = np.sum(~mask)\n",
        "        kept = np.sum(mask)\n",
        "\n",
        "        print(f\"üßπ Class {class}: removidos {removed} outliers, mantidos {kept}\")\n",
        "\n",
        "        arr = arr_clean\n",
        "\n",
        "        mean_curve = arr.mean(axis=0)\n",
        "        std_curve = arr.std(axis=0)\n",
        "\n",
        "        n_waveforms = arr.shape[0]\n",
        "\n",
        "        # =====================================================\n",
        "        #                     FINAL PLOT\n",
        "        # =====================================================\n",
        "        plt.figure(figsize=(10, 12))\n",
        "\n",
        "        plt.fill_betweenx(\n",
        "            elev_grid,\n",
        "            mean_curve - std_curve,\n",
        "            mean_curve + std_curve,\n",
        "            color=\"cornflowerblue\",\n",
        "            alpha=0.25,\n",
        "            label=\"Standard Deviation\"\n",
        "        )\n",
        "\n",
        "        plt.plot(mean_curve, elev_grid, color=\"blue\", linewidth=2.5, label=\"Mean\")\n",
        "\n",
        "        # =============== INCREASE SOURCE SIZE ===============\n",
        "        plt.xlabel(\"Waveform Amplitude\", fontsize=16, fontweight=\"bold\")\n",
        "        plt.ylabel(\"Elevation (m)\", fontsize=16, fontweight=\"bold\")\n",
        "        plt.title(f\"Waveform ‚Äì {class}\", fontsize=20, fontweight=\"bold\")\n",
        "        plt.legend(fontsize=14)\n",
        "        # ==============================================================\n",
        "\n",
        "        plt.grid(alpha=0.3)\n",
        "\n",
        "        #plt.ylim(60, 160) - transamazonica\n",
        "        #plt.xlim(0, 1000)\n",
        "\n",
        "        plt.ylim(-20, 60)\n",
        "        plt.xlim(0, 700)\n",
        "\n",
        "        plt.text(\n",
        "            0.02, 0.95,\n",
        "            f\"Waveforms used: {n_waveforms}\",\n",
        "            transform=plt.gca().transAxes,\n",
        "            fontsize=14,   # increased size\n",
        "            verticalalignment='top',\n",
        "            bbox=dict(facecolor='white', alpha=0.6, edgecolor='none')\n",
        "        )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        save_path = os.path.join(output_dir, f\"{class}_comparacao_outliers.png\")\n",
        "        plt.savefig(save_path, dpi=250)\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"üíæ Salvo: {save_path}\")\n",
        "\n",
        "\n",
        "# execute\n",
        "process(csv_path, gedi_dir, output_dir, tol)\n",
        "\n"
      ],
      "metadata": {
        "id": "TeMAtvi0aXoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================== NORMALIZATION + PLOT WITH WAVEFORMS NORMALIZED ========================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import gc\n",
        "from scipy.signal import find_peaks   # <-- ADDED\n",
        "\n",
        "# ================= PARAMETERS ====================\n",
        "gedi_dir = \"/content/gedi_data\"\n",
        "csv_path = \"/content/points/Samples_cocoa_medicilandia.csv\"\n",
        "output_dir = \"/content/waveform_plots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "tol = 1e-5\n",
        "N_GRID = 400\n",
        "NORMALIZATION_METHOD = \"minmax\"\n",
        "ELEVATION_NORM_METHOD = \"minmax\"\n",
        "PEAK_RATIO = 0.7     # <-- ONLY PEAKS ABOVE 60%\n",
        "# =================================================\n",
        "\n",
        "\n",
        "# =================================================\n",
        "#       UNIVERSAL NORMALIZATION FUNCTION\n",
        "# =================================================\n",
        "def normalize_waveform(wf, method=\"minmax\"):\n",
        "    wf = np.array(wf, dtype=float)\n",
        "\n",
        "    if method == \"minmax\":\n",
        "        wmin, wmax = wf.min(), wf.max()\n",
        "        if np.isclose(wmax, wmin):\n",
        "            return np.zeros_like(wf)\n",
        "        return (wf - wmin) / (wmax - wmin)\n",
        "\n",
        "    elif method == \"l2\":\n",
        "        norm = np.linalg.norm(wf)\n",
        "        if norm == 0:\n",
        "            return np.zeros_like(wf)\n",
        "        return wf / norm\n",
        "\n",
        "    elif method == \"zscore\":\n",
        "        mean = wf.mean()\n",
        "        std = wf.std()\n",
        "        if std < 1e-6:\n",
        "            return np.zeros_like(wf)\n",
        "        return (wf - mean) / std\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"M√©todo inv√°lido: use 'minmax', 'l2' ou 'zscore'\")\n",
        "\n",
        "# =================================================\n",
        "#               AXE Y NOMRMALIZATION\n",
        "# =================================================\n",
        "def normalize_axis(values, method=\"minmax\"):\n",
        "    values = np.array(values, dtype=float)\n",
        "\n",
        "    if method == \"minmax\":\n",
        "        vmin, vmax = values.min(), values.max()\n",
        "        if np.isclose(vmax, vmin):\n",
        "            return np.zeros_like(values)\n",
        "        return (values - vmin) / (vmax - vmin)\n",
        "\n",
        "    elif method == \"zscore\":\n",
        "        mean = values.mean()\n",
        "        std = values.std()\n",
        "        if std < 1e-6:\n",
        "            return np.zeros_like(values)\n",
        "        return (values - mean) / std\n",
        "\n",
        "    elif method == \"l2\":\n",
        "        norm = np.linalg.norm(values)\n",
        "        if norm < 1e-6:\n",
        "            return np.zeros_like(values)\n",
        "        return values / norm\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"M√©todo inv√°lido para eixo Y\")\n",
        "\n",
        "\n",
        "# =================================================\n",
        "# NEW FUNCTION: COUNT OF PEAKS GREATER THAN 60%\n",
        "# =================================================\n",
        "def count_large_peaks_ratio(wave, ratio=0.6, distance=5):\n",
        "    \"\"\"\n",
        "    Conta picos cuja altura seja maior que (ratio * pico m√°ximo da waveform).\n",
        "    ratio: entre 0 e 1 (ex: 0.6 = picos acima de 60% do valor m√°ximo)\n",
        "    \"\"\"\n",
        "    max_val = wave.max()\n",
        "    height_min = max_val * ratio\n",
        "    peaks, props = find_peaks(wave, height=height_min, distance=distance)\n",
        "    return len(peaks), peaks, props[\"peak_heights\"]\n",
        "\n",
        "\n",
        "# =================================================\n",
        "#                 EXISTING FUNCTION\n",
        "# =================================================\n",
        "def find_shot_by_coord_stream(f, beam, lat_alvo, lon_alvo, tol, chunk=20000):\n",
        "    lat = f[f\"{beam}/geolocation/latitude_bin0\"]\n",
        "    lon = f[f\"{beam}/geolocation/longitude_bin0\"]\n",
        "    shots = f[f\"{beam}/shot_number\"]\n",
        "\n",
        "    total = len(lat)\n",
        "    for i in range(0, total, chunk):\n",
        "        end = min(i + chunk, total)\n",
        "        block_lat = lat[i:end]\n",
        "        block_lon = lon[i:end]\n",
        "\n",
        "        idx = np.where(\n",
        "            (np.abs(block_lat - lat_alvo) <= tol) &\n",
        "            (np.abs(block_lon - lon_alvo) <= tol)\n",
        "        )[0]\n",
        "\n",
        "        if len(idx) > 0:\n",
        "            return int(shots[i + idx[0]])\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_waveform_minimal(f, beam, shot):\n",
        "    shots = f[f\"{beam}/shot_number\"]\n",
        "\n",
        "    for i in range(0, shots.shape[0], 20000):\n",
        "        end = min(i + 20000, shots.shape[0])\n",
        "        block = shots[i:end]\n",
        "        idx = np.where(block == shot)[0]\n",
        "        if len(idx):\n",
        "            idx = i + idx[0]\n",
        "            break\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    start = int(f[f\"{beam}/rx_sample_start_index\"][idx])\n",
        "    count = int(f[f\"{beam}/rx_sample_count\"][idx])\n",
        "\n",
        "    elev0 = float(f[f\"{beam}/geolocation/elevation_bin0\"][idx])\n",
        "    elev_last = float(f[f\"{beam}/geolocation/elevation_lastbin\"][idx])\n",
        "\n",
        "    waveform = f[f\"{beam}/rxwaveform\"][start:start + count]\n",
        "    elevations = np.linspace(elev0, elev_last, len(waveform))\n",
        "\n",
        "    return waveform, elevations\n",
        "\n",
        "\n",
        "def rms_distance(a, b):\n",
        "    return np.sqrt(np.mean((a - b) ** 2))\n",
        "\n",
        "\n",
        "# =================================================\n",
        "#       EXECUTION\n",
        "# =================================================\n",
        "def process(csv_path, gedi_dir, output_dir, tol):\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    class_waveforms = {}\n",
        "    class_elev_grids = {}\n",
        "\n",
        "    files = [os.path.join(gedi_dir, f) for f in os.listdir(gedi_dir) if f.endswith(\".h5\")]\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        lat, lon, class = row[\"latitude\"], row[\"longitude\"], row[\"class\"]\n",
        "        print(f\"\\nüîç Procurando: class {class}, ponto {idx+1}\")\n",
        "\n",
        "        if class not in class_waveforms:\n",
        "            class_waveforms[class] = []\n",
        "            class_elev_grids[class] = None\n",
        "\n",
        "        found = False\n",
        "\n",
        "        for fp in files:\n",
        "            with h5py.File(fp, \"r\") as f:\n",
        "\n",
        "                for beam in f.keys():\n",
        "                    if f\"{beam}/geolocation/latitude_bin0\" not in f:\n",
        "                        continue\n",
        "\n",
        "                    shot = find_shot_by_coord_stream(f, beam, lat, lon, tol)\n",
        "                    if not shot:\n",
        "                        continue\n",
        "\n",
        "                    print(f\"‚úî Encontrado em {fp} ‚Üí {beam}, shot {shot}\")\n",
        "\n",
        "                    result = extract_waveform_minimal(f, beam, shot)\n",
        "                    if not result:\n",
        "                        continue\n",
        "\n",
        "                    wf, elev = result\n",
        "\n",
        "                    if class_elev_grids[class] is None:\n",
        "                        class_elev_grids[class] = np.linspace(max(elev), min(elev), N_GRID)\n",
        "\n",
        "                    elev_grid = class_elev_grids[class]\n",
        "\n",
        "                    wf_interp = np.interp(elev_grid, elev[::-1], wf[::-1])\n",
        "                    wf_interp = normalize_waveform(wf_interp, method=NORMALIZATION_METHOD)\n",
        "\n",
        "                    class_waveforms[class].append(wf_interp)\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if found:\n",
        "                break\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    # ====================================================\n",
        "    #            COMPARISON AND REMOVAL OUTLIERS\n",
        "    # ====================================================\n",
        "    for class in class_waveforms.keys():\n",
        "\n",
        "        wave_list = class_waveforms[class]\n",
        "        elev_grid = class_elev_grids[class]\n",
        "\n",
        "        if len(wave_list) == 0:\n",
        "            print(f\"‚ö† Class {class} n√£o teve nenhuma waveform encontrada.\")\n",
        "            continue\n",
        "\n",
        "        arr = np.vstack(wave_list)\n",
        "\n",
        "        prelim_mean = arr.mean(axis=0)\n",
        "        distances = np.array([rms_distance(w, prelim_mean) for w in arr])\n",
        "\n",
        "        mean_dist = distances.mean()\n",
        "        std_dist = distances.std()\n",
        "        threshold = mean_dist + 3 * std_dist\n",
        "\n",
        "        mask = distances <= threshold\n",
        "        arr_clean = arr[mask]\n",
        "\n",
        "        removed = np.sum(~mask)\n",
        "        kept = np.sum(mask)\n",
        "\n",
        "        print(f\"üßπ Class {class}: removidos {removed} outliers, mantidos {kept}\")\n",
        "\n",
        "        arr = arr_clean\n",
        "\n",
        "        mean_curve = arr.mean(axis=0)\n",
        "        std_curve = arr.std(axis=0)\n",
        "\n",
        "        # =====================================================\n",
        "        #         CONTING OF LARGE PEAKS(>70%)\n",
        "        # =====================================================\n",
        "        num_large_peaks, peaks_large, heights_large = count_large_peaks_ratio(\n",
        "            mean_curve, ratio=PEAK_RATIO\n",
        "        )\n",
        "\n",
        "\n",
        "        # =====================================================\n",
        "        #                     FINAL PLOT\n",
        "        # =====================================================\n",
        "        elev_norm = normalize_axis(elev_grid, method=ELEVATION_NORM_METHOD)\n",
        "\n",
        "        plt.figure(figsize=(10, 12))\n",
        "\n",
        "        plt.fill_betweenx(\n",
        "            elev_norm,\n",
        "            mean_curve - std_curve,\n",
        "            mean_curve + std_curve,\n",
        "            color=\"cornflowerblue\",\n",
        "            alpha=0.25,\n",
        "            label=\"Standard Deviation\"\n",
        "        )\n",
        "\n",
        "        plt.plot(mean_curve, elev_norm, color=\"blue\", linewidth=2.5, label=\"Mean\")\n",
        "\n",
        "        #  Marks the large peaks in red\n",
        "        plt.scatter(mean_curve[peaks_large], elev_norm[peaks_large],\n",
        "                    color=\"red\", s=60, label=\"Peaks >70%\")\n",
        "\n",
        "        plt.xlabel(\"Normalized Waveform\", fontsize=18, fontweight=\"bold\")\n",
        "        plt.ylabel(\"Normalized Elevation\", fontsize=18, fontweight=\"bold\")\n",
        "\n",
        "        plt.title(\n",
        "            f\"Waveform ‚Äì {class}\\n\"\n",
        "            f\"WF norm: {NORMALIZATION_METHOD} | Elev norm: {ELEVATION_NORM_METHOD}\",\n",
        "            fontsize=20, fontweight=\"bold\"\n",
        "        )\n",
        "\n",
        "        plt.legend(fontsize=14)\n",
        "\n",
        "        # Text with count\n",
        "        plt.text(\n",
        "            0.02, 0.02,\n",
        "            f\"Waveforms: {kept}\\n\"\n",
        "            f\"Peaks >70%: {num_large_peaks}\",\n",
        "            transform=plt.gca().transAxes,\n",
        "            fontsize=16,\n",
        "            bbox=dict(facecolor='white', alpha=0.6)\n",
        "        )\n",
        "\n",
        "        plt.tick_params(axis='both', labelsize=18)\n",
        "\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # ===== SAVE THE PLOT =====\n",
        "        save_path = os.path.join(output_dir, f\"{class}_comparacao_outliers_norm.png\")\n",
        "        plt.savefig(save_path, dpi=250)\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"üíæ Salvo: {save_path}\")\n",
        "\n",
        "\n",
        "# execute\n",
        "process(csv_path, gedi_dir, output_dir, tol)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6bYg8hImhTax"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
